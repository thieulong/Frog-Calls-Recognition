{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXQAcreKedWU"
      },
      "outputs": [],
      "source": [
        "#@title Imports. { vertical-output: true }\n",
        "\n",
        "import os\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from perch_hoplite.agile import audio_loader\n",
        "from perch_hoplite.agile import classifier\n",
        "from perch_hoplite.agile import classifier_data\n",
        "from perch_hoplite.agile import embedding_display\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.db  import brutalism\n",
        "from perch_hoplite.db import score_functions\n",
        "from perch_hoplite.db  import search_results\n",
        "from perch_hoplite.db import sqlite_usearch_impl\n",
        "from perch_hoplite.zoo import model_configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz63sWKEedWU"
      },
      "outputs": [],
      "source": [
        "#@title Load model and connect to database. { vertical-output: true }\n",
        "\n",
        "#@markdown Location of database containing audio embeddings.\n",
        "db_path = ''  #@param {type:'string'}\n",
        "#@markdown Identifier (eg, name) to attach to labels produced during validation.\n",
        "annotator_id = 'linnaeus'  #@param {type:'string'}\n",
        "\n",
        "db = sqlite_usearch_impl.SQLiteUsearchDB.create(db_path)\n",
        "db_model_config = db.get_metadata('model_config')\n",
        "embed_config = db.get_metadata('audio_sources')\n",
        "model_class = model_configs.get_model_class(db_model_config.model_key)\n",
        "embedding_model = model_class.from_config(db_model_config.model_config)\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "if hasattr(embedding_model, 'window_size_s'):\n",
        "  window_size_s = embedding_model.window_size_s\n",
        "else:\n",
        "  window_size_s = 5.0\n",
        "audio_filepath_loader = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=embedding_model.sample_rate,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVdLJJd9gnjo"
      },
      "source": [
        "# Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ig3L5dsy3mr"
      },
      "outputs": [],
      "source": [
        "#@title Load query audio. { vertical-output: true }\n",
        "\n",
        "#@markdown The `query_uri` can be a URL, filepath, or Xeno-Canto ID\n",
        "#@markdown (like `xc777802`, containing an Eastern Whipbird (`easwhi1`)).\n",
        "query_uri = 'xc777802'  #@param {type:'string'}\n",
        "query_label = 'easwhi1'  #@param {type:'string'}\n",
        "\n",
        "query = embedding_display.QueryDisplay(\n",
        "    uri=query_uri, offset_s=0.0, window_size_s=5.0, sample_rate_hz=32000)\n",
        "_ = query.display_interactive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHUJ_NwQWZNB"
      },
      "outputs": [],
      "source": [
        "#@title Embed the Query and Search. { vertical-output: true }\n",
        "\n",
        "#@markdown Number of results to find and display.\n",
        "num_results = 50  #@param\n",
        "query_embedding = embedding_model.embed(\n",
        "    query.get_audio_window()).embeddings[0, 0]\n",
        "\n",
        "#@markdown If checked, search for examples\n",
        "#@markdown near a particular target score.\n",
        "target_sampling = False  #@param {type: 'boolean'}\n",
        "\n",
        "#@markdown When target sampling, target this score.\n",
        "target_score = -1.0  #@param\n",
        "if not target_sampling:\n",
        "  target_score = None\n",
        "\n",
        "#@markdown If True, search the full DB. Otherwise, use approximate\n",
        "#@markdown nearest-neighbor search.\n",
        "exact_search = False  #@param {type: 'boolean'}\n",
        "\n",
        "if exact_search:\n",
        "  target_score = None\n",
        "  score_fn = score_functions.get_score_fn('dot', target_score=target_score)\n",
        "  results, all_scores = brutalism.threaded_brute_search(\n",
        "      db, query_embedding, num_results, score_fn=score_fn)\n",
        "  # TODO(tomdenton): Better histogram when target sampling.\n",
        "  _ = plt.hist(all_scores, bins=100)\n",
        "  hit_scores = [r.sort_score for r in results.search_results]\n",
        "  plt.scatter(hit_scores, np.zeros_like(hit_scores), marker='|',\n",
        "              color='r', alpha=0.5)\n",
        "else:\n",
        "  ann_matches = db.ui.search(query_embedding, count=num_results)\n",
        "  results = search_results.TopKSearchResults(top_k=num_results)\n",
        "  for k, d in zip(ann_matches.keys, ann_matches.distances):\n",
        "    results.update(search_results.SearchResult(k, d))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y21fWjEwXj68"
      },
      "outputs": [],
      "source": [
        "#@title Display Results. { vertical-output: true }\n",
        "\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results, db, sample_rate_hz=32000, frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader)\n",
        "display_results.display(positive_labels=[query_label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3sIkOqlXzKB"
      },
      "outputs": [],
      "source": [
        "#@title Save data labels. { vertical-output: true }\n",
        "\n",
        "prev_lbls, new_lbls = 0, 0\n",
        "for lbl in display_results.harvest_labels(annotator_id):\n",
        "  check = db.insert_label(lbl, skip_duplicates=True)\n",
        "  new_lbls += check\n",
        "  prev_lbls += (1 - check)\n",
        "print('\\nnew_lbls: ', new_lbls)\n",
        "print('\\nprev_lbls: ', prev_lbls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o65wpjvyYft-"
      },
      "source": [
        "# Classify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtsJkgcPYg6z"
      },
      "outputs": [],
      "source": [
        "#@title Classifier training. { vertical-output: true }\n",
        "\n",
        "#@markdown Set of labels to classify. If None, auto-populated from the DB.\n",
        "target_labels = None  #@param\n",
        "\n",
        "#@markdown Classifier traning hyperparams. These should not require tuning.\n",
        "learning_rate = 1e-3  #@param\n",
        "weak_neg_weight = 0.05  #@param\n",
        "l2_mu = 0.000  #@param\n",
        "num_steps = 128  #@param\n",
        "\n",
        "train_ratio = 0.9  #@param\n",
        "batch_size = 128  #@param\n",
        "weak_negatives_batch_size = 128  #@param\n",
        "loss_fn_name = 'bce'  #@param ['hinge', 'bce']\n",
        "\n",
        "data_manager = classifier_data.AgileDataManager(\n",
        "    target_labels=target_labels,\n",
        "    db=db,\n",
        "    train_ratio=train_ratio,\n",
        "    min_eval_examples=1,\n",
        "    batch_size=batch_size,\n",
        "    weak_negatives_batch_size=weak_negatives_batch_size,\n",
        "    rng=np.random.default_rng(seed=5))\n",
        "print('Training for target labels : ')\n",
        "print(data_manager.get_target_labels())\n",
        "linear_classifier, eval_scores = classifier.train_linear_classifier(\n",
        "    data_manager=data_manager,\n",
        "    learning_rate=learning_rate,\n",
        "    weak_neg_weight=weak_neg_weight,\n",
        "    num_train_steps=num_steps,\n",
        ")\n",
        "print('\\n' + '-' * 80)\n",
        "top1 = eval_scores['top1_acc']\n",
        "print(f'top-1      {top1:.3f}')\n",
        "rocauc = eval_scores['roc_auc']\n",
        "print(f'roc_auc    {rocauc:.3f}')\n",
        "cmap = eval_scores['cmap']\n",
        "print(f'cmap       {cmap:.3f}')\n",
        "\n",
        "# Save linear classifier.\n",
        "linear_classifier.save(os.path.join(db_path, 'agile_classifier_v2.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3N6dzhetkG1"
      },
      "outputs": [],
      "source": [
        "#@title Review Classifier Results. { vertical-output: true }\n",
        "\n",
        "#@markdown Number of results to find and display.\n",
        "target_label = 'easwhi1'  #@param {type:'string'}\n",
        "num_results = 50  #@param\n",
        "\n",
        "target_label_idx = data_manager.get_target_labels().index(target_label)\n",
        "class_query = linear_classifier.beta[:, target_label_idx]\n",
        "bias = linear_classifier.beta_bias[target_label_idx]\n",
        "\n",
        "#@markdown Number of (randomly selected) database entries to search over.\n",
        "sample_size = 1_000_000  #@param\n",
        "\n",
        "#@markdown Whether to use margin-sampling. If checked, search for examples\n",
        "#@markdown with logits near a particular target score (usually 0).\n",
        "margin_sampling = False  #@param {type: 'boolean'}\n",
        "\n",
        "#@markdown When margin sampling, target this logit.\n",
        "margin_target_score = -0.0  #@param\n",
        "if not margin_sampling:\n",
        "  margin_target_score = None\n",
        "score_fn = score_functions.get_score_fn(\n",
        "    'dot', bias=bias, target_score=margin_target_score)\n",
        "results, all_scores = brutalism.threaded_brute_search(\n",
        "    db, class_query, num_results, score_fn=score_fn,\n",
        "    sample_size=sample_size)\n",
        "\n",
        "# TODO(tomdenton): Better histogram when margin sampling.\n",
        "_ = plt.hist(all_scores, bins=100)\n",
        "hit_scores = [r.sort_score for r in results.search_results]\n",
        "plt.scatter(hit_scores, np.zeros_like(hit_scores), marker='|',\n",
        "            color='r', alpha=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiNoGhyoDF2v"
      },
      "outputs": [],
      "source": [
        "#@title Display Results. { vertical-output: true }\n",
        "\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results, db, sample_rate_hz=32000, frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader)\n",
        "display_results.display(positive_labels=[target_label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEk15jw_B8xL"
      },
      "outputs": [],
      "source": [
        "#@title Save data labels. { vertical-output: true }\n",
        "\n",
        "prev_lbls, new_lbls = 0, 0\n",
        "for lbl in display_results.harvest_labels(annotator_id):\n",
        "  check = db.insert_label(lbl, skip_duplicates=True)\n",
        "  new_lbls += check\n",
        "  prev_lbls += (1 - check)\n",
        "print('\\nnew_lbls: ', new_lbls)\n",
        "print('\\nprev_lbls: ', prev_lbls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBH-2kz4SaS2"
      },
      "outputs": [],
      "source": [
        "#@title Run inference with trained classifier. { vertical-output: true }\n",
        "\n",
        "output_csv_filepath = ''  #@param {type:'string'}\n",
        "logit_threshold = 1.0  #@param\n",
        "# Set labels to a tuple of desired labels if you want to run inference on a\n",
        "# subset of the labels.\n",
        "labels = None  #@param\n",
        "\n",
        "classifier.write_inference_csv(\n",
        "    linear_classifier, db, output_csv_filepath, logit_threshold, labels=labels)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
